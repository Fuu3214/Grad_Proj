{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This tutorial shows how to generate adversarial examples\n",
    "using JSMA in white-box setting.\n",
    "The original paper can be found at:\n",
    "https://arxiv.org/abs/1511.07528\n",
    "\"\"\"\n",
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.loss import CrossEntropy\n",
    "from cleverhans.attacks import CarliniWagnerL2\n",
    "from cleverhans.attacks import SaliencyMapMethod\n",
    "from cleverhans.attacks import DeepFool\n",
    "from cleverhans.utils import other_classes, set_log_level\n",
    "from cleverhans.utils import pair_visual, grid_visual, AccuracyReport\n",
    "from cleverhans.utils_tf import model_eval, model_argmax\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from cleverhans_model import CleverhansModel\n",
    "from model import Model as My_model\n",
    "\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "import math\n",
    "from random import choice\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./models/nat\"\n",
    "\n",
    "num_examples = 10\n",
    "batch_size = 2\n",
    "num_batches = int(math.ceil(num_examples / batch_size))\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sess, img):\n",
    "    x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "    c_model.fprop(x)\n",
    "    return sess.run(c_model.get_pred(), feed_dict = {x: img})\n",
    "def plot(img):\n",
    "    plt.imshow(np.resize(img,[28,28]), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_graph(model_dir):\n",
    "    tf.reset_default_graph()\n",
    "    # print(scope_vars)\n",
    "    # x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "\n",
    "    model = My_model()\n",
    "    c_model = CleverhansModel('CNN', 10, model)\n",
    "    checkpoint = tf.train.latest_checkpoint(model_dir)\n",
    "    reader=pywrap_tensorflow.NewCheckpointReader(checkpoint)\n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto()\n",
    "    config.log_device_placement=False\n",
    "    config.allow_soft_placement=True\n",
    "    config.gpu_options.allow_growth=True\n",
    "    session = tf.Session(config=config)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver.restore(session, checkpoint)\n",
    "    return session, c_model\n",
    "\n",
    "def batch_attack(data, attack, **params):\n",
    "    x_adv = []\n",
    "    for ibatch in range(num_batches):\n",
    "        bstart = ibatch * batch_size\n",
    "        bend = min(bstart + batch_size, num_examples)\n",
    "        print('batch size: {}'.format(bend - bstart))\n",
    "\n",
    "        x_batch = data[bstart:bend, :]\n",
    "\n",
    "        x_batch_adv = attack.generate_np(x_batch, **params)\n",
    "        \n",
    "        x_adv = x_adv + x_batch_adv.tolist()\n",
    "        \n",
    "    return x_adv\n",
    "\n",
    "def save_npy(algm, x_adv, filename = '/adv.npy'):\n",
    "    path = './adv_test/' + algm + filename\n",
    "    x_adv_np = np.asarray(x_adv)\n",
    "    np.save(path, x_adv_np)\n",
    "    print(\"saved to: \" + path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nat/checkpoint-7800\n"
     ]
    }
   ],
   "source": [
    "session, c_model = init_graph(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-05-06 13:30:04,950 cleverhans] Constructing new graph for attack SaliencyMapMethod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crafting 10 adversarial examples\n",
      "--------------------------------------\n",
      "Attacking input batch 1/5\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Attacking input batch 2/5\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Attacking input batch 3/5\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Attacking input batch 4/5\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Attacking input batch 5/5\n",
      "--------------------------------------\n",
      "saved to: ./adv_test/jsma/adv.npy\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Craft adversarial examples using the Jacobian-based saliency map approach\n",
    "###########################################################################\n",
    "\n",
    "# y = tf.placeholder(tf.int64, shape = [None])\n",
    "print(\"=============================================================\")\n",
    "print('JSMA: Crafting ' + str(num_examples) +\n",
    "    ' adversarial examples')\n",
    "\n",
    "jsma = SaliencyMapMethod(c_model, sess=session)\n",
    "jsma_params = {'theta': 1., 'gamma': 0.1,\n",
    "             'clip_min': 0., 'clip_max': 1.,\n",
    "             'y_target': None}\n",
    "\n",
    "x_adv = [] # adv accumulator\n",
    "\n",
    "for sample_ind in xrange(0, num_examples):\n",
    "    print('--------------------------------------')\n",
    "    if(sample_ind % batch_size == 0):\n",
    "        print('Attacking input batch %i/%i' % (sample_ind/batch_size + 1, num_examples/batch_size))\n",
    "    sample = x_test[sample_ind:(sample_ind + 1)]\n",
    "    adv = jsma.generate_np(sample, **jsma_params)\n",
    "    x_adv.append(adv)\n",
    "    \n",
    "x_adv = np.concatenate(x_adv, axis=0)\n",
    "save_npy('jsma', x_adv)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nat/checkpoint-7800\n"
     ]
    }
   ],
   "source": [
    "session, c_model = init_graph(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-05-06 13:26:57,060 cleverhans] Constructing new graph for attack CarliniWagnerL2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over 5 batches\n",
      "Crafting 10 adversarial examples\n",
      "This could take some time ...\n",
      "batch size: 2\n",
      "batch size: 2\n",
      "batch size: 2\n",
      "batch size: 2\n",
      "batch size: 2\n",
      "saved to: ./adv_test/cw/adv.npy\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = .001\n",
    "CW_LEARNING_RATE = .2\n",
    "ATTACK_ITERATIONS = 100\n",
    "\n",
    "print('Iterating over {} batches'.format(num_batches))\n",
    "\n",
    "# x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "# y = tf.placeholder(tf.int64, shape = [None])\n",
    "\n",
    "###########################################################################\n",
    "# Craft adversarial examples using Carlini and Wagner's approach\n",
    "###########################################################################\n",
    "print(\"=============================================================\")\n",
    "print('CW: Crafting ' + str(num_examples) + ' adversarial examples')\n",
    "print(\"This could take some time ...\")\n",
    "\n",
    "# Instantiate a CW attack object\n",
    "cw = CarliniWagnerL2(c_model, sess=session)\n",
    "\n",
    "cw_params = {'binary_search_steps': 1,\n",
    "               \"y_target\": None,\n",
    "               'max_iterations': ATTACK_ITERATIONS,\n",
    "               'learning_rate': CW_LEARNING_RATE,\n",
    "               'batch_size': batch_size,\n",
    "               'initial_const': 10}\n",
    "\n",
    "x_adv = batch_attack(x_test, cw, **cw_params)\n",
    "save_npy('cw', x_adv)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nat/checkpoint-7800\n"
     ]
    }
   ],
   "source": [
    "session, c_model = init_graph(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-05-06 13:26:59,279 cleverhans] Constructing new graph for attack FastGradientMethod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crafting 10 adversarial examples\n",
      "batch size: 2\n",
      "WARNING:tensorflow:From /home/xdjf/anaconda3/envs/my_env/lib/python3.6/site-packages/cleverhans/compat.py:124: calling softmax_cross_entropy_with_logits_v2_helper (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "batch size: 2\n",
      "batch size: 2\n",
      "batch size: 2\n",
      "batch size: 2\n",
      "saved to: ./adv_test/fgsm/adv.npy\n"
     ]
    }
   ],
   "source": [
    "fgsm_params = {\n",
    "  'eps': 0.3,\n",
    "  'clip_min': 0.,\n",
    "  'clip_max': 1.\n",
    "}\n",
    "\n",
    "# Set TF random seed to improve reproducibility\n",
    "tf.set_random_seed(2333)\n",
    "\n",
    "# x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "# y = tf.placeholder(tf.int64, shape = [None])\n",
    "\n",
    "###########################################################################\n",
    "# Craft adversarial examples using FGSM\n",
    "###########################################################################\n",
    "print(\"=============================================================\")\n",
    "print('FGSM: Crafting ' + str(num_examples) + ' adversarial examples')\n",
    "\n",
    "fgsm = FastGradientMethod(c_model, sess=session)\n",
    "x_adv = batch_attack(x_test, fgsm, **fgsm_params)\n",
    "save_npy('fgsm', x_adv)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nat/checkpoint-7800\n"
     ]
    }
   ],
   "source": [
    "session, c_model = init_graph(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-05-06 13:42:14,137 cleverhans] Constructing new graph for attack DeepFool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEPFOOL: =============================================================\n",
      "Crafting 10 adversarial examples\n",
      "batch size: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-05-06 13:42:15,831 cleverhans] Attack result at iteration 5 is [7 2]\n",
      "[INFO 2019-05-06 13:42:15,892 cleverhans] Attack result at iteration 10 is [7 2]\n",
      "[INFO 2019-05-06 13:42:15,949 cleverhans] Attack result at iteration 15 is [3 1]\n",
      "[INFO 2019-05-06 13:42:15,952 cleverhans] 2 out of 2 become adversarial examples at iteration 15\n",
      "[INFO 2019-05-06 13:42:16,011 cleverhans] Attack result at iteration 5 is [1 0]\n",
      "[INFO 2019-05-06 13:42:16,069 cleverhans] Attack result at iteration 10 is [1 0]\n",
      "[INFO 2019-05-06 13:42:16,110 cleverhans] Attack result at iteration 14 is [8 2]\n",
      "[INFO 2019-05-06 13:42:16,111 cleverhans] 2 out of 2 become adversarial examples at iteration 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 2\n",
      "batch size: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-05-06 13:42:16,168 cleverhans] Attack result at iteration 5 is [4 1]\n",
      "[INFO 2019-05-06 13:42:16,221 cleverhans] Attack result at iteration 10 is [4 1]\n",
      "[INFO 2019-05-06 13:42:16,245 cleverhans] Attack result at iteration 12 is [9 7]\n",
      "[INFO 2019-05-06 13:42:16,246 cleverhans] 2 out of 2 become adversarial examples at iteration 12\n",
      "[INFO 2019-05-06 13:42:16,301 cleverhans] Attack result at iteration 5 is [4 9]\n",
      "[INFO 2019-05-06 13:42:16,355 cleverhans] Attack result at iteration 10 is [8 9]\n",
      "[INFO 2019-05-06 13:42:16,388 cleverhans] Attack result at iteration 13 is [8 4]\n",
      "[INFO 2019-05-06 13:42:16,389 cleverhans] 2 out of 2 become adversarial examples at iteration 13\n",
      "[INFO 2019-05-06 13:42:16,448 cleverhans] Attack result at iteration 5 is [5 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 2\n",
      "batch size: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-05-06 13:42:16,501 cleverhans] Attack result at iteration 10 is [5 9]\n",
      "[INFO 2019-05-06 13:42:16,522 cleverhans] Attack result at iteration 12 is [6 7]\n",
      "[INFO 2019-05-06 13:42:16,523 cleverhans] 2 out of 2 become adversarial examples at iteration 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: ./adv_test/deepfool/adv.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################################################################\n",
    "# Craft adversarial examples using FGSM\n",
    "###########################################################################\n",
    "print(\"DEEPFOOL: =============================================================\")\n",
    "print('Crafting ' + str(num_examples) + ' adversarial examples')\n",
    "\n",
    "deepfool = DeepFool(c_model, sess=session)\n",
    "x_adv = batch_attack(x_test, deepfool)\n",
    "save_npy('deepfool', x_adv)\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(x_adv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_my_model(model_dir):\n",
    "    tf.reset_default_graph()\n",
    "    # print(scope_vars)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "    y = tf.placeholder(tf.int64, shape = [None])\n",
    "    \n",
    "    model = My_model()\n",
    "    model.build_and_eval(x, y)\n",
    "    \n",
    "    checkpoint = tf.train.latest_checkpoint(model_dir)\n",
    "    reader=pywrap_tensorflow.NewCheckpointReader(checkpoint)\n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto()\n",
    "    config.log_device_placement=False\n",
    "    config.allow_soft_placement=True\n",
    "    config.gpu_options.allow_growth=True\n",
    "    session = tf.Session(config=config)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver.restore(session, checkpoint)\n",
    "    return session, model\n",
    "\n",
    "def generate_adv_attr(session, model, img_path, tar_path, num_examples = num_examples):\n",
    "\n",
    "    \n",
    "    \n",
    "    adv_test = np.load(img_path)\n",
    "\n",
    "    # train_total_data = np.column_stack((adv_test,true_labels))\n",
    "\n",
    "\n",
    "    # In[16]:\n",
    "\n",
    "\n",
    "    labeled_pred = model.softmax_layer[:,model.y_input[0]]\n",
    "    grad = tf.gradients(labeled_pred, model.x_input)\n",
    "    def integrated_gradient(img, target_label_index, steps = 50, baseline=None):\n",
    "        if baseline is None:\n",
    "            baseline = 0*img\n",
    "        assert(baseline.shape == img.shape)\n",
    "        steps=steps\n",
    "\n",
    "        # Scale input and compute gradients.\n",
    "        scaled_inputs = [baseline + (float(i)/steps)*(img-baseline) for i in range(0, steps+1)]\n",
    "\n",
    "        gradient = session.run(grad, feed_dict = {model.x_input:np.squeeze(scaled_inputs),model.y_input:target_label_index})\n",
    "        avg_grads = np.average(gradient[0][:-1], axis=0)\n",
    "        integrated_gradients = (img-baseline)*avg_grads  # shape: <inp.shape>\n",
    "        return integrated_gradients\n",
    "\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "\n",
    "    feature_attributions = []\n",
    "    for i in range(num_examples):\n",
    "        x = adv_test[i]\n",
    "        y = session.run(model.y_pred, feed_dict={model.x_input: [x]})[0]\n",
    "        feature_attributions.append(integrated_gradient(x, [y]))\n",
    "\n",
    "\n",
    "    print('Storing examples')\n",
    "    feature_attributions = np.asarray(feature_attributions)\n",
    "    np.save(tar_path, feature_attributions)\n",
    "    print('Examples stored in {}'.format(tar_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = \"./models/\"\n",
    "adv_dir = \"./adv_test/\"\n",
    "tar_dir = \"./features/test/\"\n",
    "\n",
    "algm = ['/fgsm/','/cw/','/jsma/','/deepfool/']\n",
    "# loss = ['/xent/', '/cw/']\n",
    "model_name = '/nat/'\n",
    "name = 'adv.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "model_path:./models//nat/\n",
      "INFO:tensorflow:Restoring parameters from ./models//nat/checkpoint-7800\n",
      "adv_path:./adv_test//fgsm/adv.npy\n",
      "Storing examples\n",
      "Examples stored in ./features/test//fgsm/adv.npy\n",
      "=============================================================\n",
      "model_path:./models//nat/\n",
      "INFO:tensorflow:Restoring parameters from ./models//nat/checkpoint-7800\n",
      "adv_path:./adv_test//cw/adv.npy\n",
      "Storing examples\n",
      "Examples stored in ./features/test//cw/adv.npy\n",
      "=============================================================\n",
      "model_path:./models//nat/\n",
      "INFO:tensorflow:Restoring parameters from ./models//nat/checkpoint-7800\n",
      "adv_path:./adv_test//jsma/adv.npy\n",
      "Storing examples\n",
      "Examples stored in ./features/test//jsma/adv.npy\n",
      "=============================================================\n",
      "model_path:./models//nat/\n",
      "INFO:tensorflow:Restoring parameters from ./models//nat/checkpoint-7800\n",
      "adv_path:./adv_test//deepfool/adv.npy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1,) for Tensor 'Placeholder:0', which has shape '(?, 784)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3fa9444cd507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adv_path:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgenerate_adv_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-1cf000a783d6>\u001b[0m in \u001b[0;36mgenerate_adv_attr\u001b[0;34m(session, model, img_path, tar_path, num_examples)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mfeature_attributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintegrated_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1,) for Tensor 'Placeholder:0', which has shape '(?, 784)'"
     ]
    }
   ],
   "source": [
    "\n",
    "# mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "# labels = mnist.test.labels\n",
    "\n",
    "for a in range(len(algm)):\n",
    "    print(\"=============================================================\")\n",
    "    a_path = algm[a] + name\n",
    "    model_path = model_dir + model_name\n",
    "    print(\"model_path:\" + model_path)\n",
    "    session, model = init_my_model(model_path)\n",
    "    \n",
    "    adv_path = adv_dir + a_path\n",
    "    tar_path = tar_dir + a_path\n",
    "\n",
    "    print(\"adv_path:\" + adv_path)\n",
    "    generate_adv_attr(session, model, adv_path, tar_path)\n",
    "    session.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
